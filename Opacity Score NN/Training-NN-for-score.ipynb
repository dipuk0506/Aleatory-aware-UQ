{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "reduced-fantasy",
   "metadata": {
    "papermill": {
     "duration": 0.012667,
     "end_time": "2021-11-08T03:04:31.586790",
     "exception": false,
     "start_time": "2021-11-08T03:04:31.574123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NN training for Score\n",
    "\n",
    "## 1. Posteriors and Scores\n",
    "### a. Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "excess-destination",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T03:04:31.621787Z",
     "iopub.status.busy": "2021-11-08T03:04:31.620750Z",
     "iopub.status.idle": "2021-11-08T03:17:52.668056Z",
     "shell.execute_reply": "2021-11-08T03:17:52.666538Z",
     "shell.execute_reply.started": "2021-11-08T01:59:34.230226Z"
    },
    "papermill": {
     "duration": 801.069841,
     "end_time": "2021-11-08T03:17:52.668435",
     "exception": false,
     "start_time": "2021-11-08T03:04:31.598594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train points and labels (5702, 2) (5702,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd  \n",
    "\n",
    "k_nearest = 10\n",
    "distance_offset =1e-5\n",
    "\n",
    "with open('../input/siim-fisabio-rsna-classification-tl/train.npy', 'rb') as f:\n",
    "    points_train = np.load(f)\n",
    "    labels_train = np.load(f)\n",
    "\n",
    "points = points_train\n",
    "labels = labels_train\n",
    "print('Shape of train points and labels',points.shape, labels.shape)\n",
    "\n",
    "# Using the same variable names for ease and memory efficiency\n",
    "X1 =np.zeros([len(labels)])\n",
    "X2 =np.zeros([len(labels)])\n",
    "y =np.zeros([len(labels)])\n",
    "\n",
    "index_0 =0\n",
    "index_1=0\n",
    "ms_distance = np.zeros([len(labels_train),2])\n",
    "\n",
    "for validation_index in range(len(labels)):\n",
    "    point = points[validation_index,:]\n",
    "    \n",
    "    for iter1 in range(len(labels_train)):\n",
    "        ms_distance[iter1,:] = [np.mean(np.power(point- points_train[iter1,:],2)), labels_train[iter1]]\n",
    "\n",
    "    sorted_array = ms_distance[np.argsort(ms_distance[:, 0])]\n",
    "\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for iter1 in range(k_nearest):\n",
    "        numerator = numerator + sorted_array[iter1,1]/(distance_offset + sorted_array[iter1,0]) # numerator increases only for label=1 \n",
    "        denominator = denominator + 1/(distance_offset + sorted_array[iter1,0])\n",
    "\n",
    "    opacity_probability = numerator/denominator\n",
    "    \n",
    "    X1[validation_index] = point[0]\n",
    "    X2[validation_index] = point[1]\n",
    "    y[validation_index] = opacity_probability\n",
    "    #print([point[0], point[1], opacity_probability])  \n",
    "    \n",
    "    \n",
    "\n",
    "dict = {'Input1': X1, 'Input2': X2, 'Output': y}  \n",
    "df = pd.DataFrame(dict) \n",
    "df.to_csv('Data_Train.csv', header=True, index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-annex",
   "metadata": {
    "papermill": {
     "duration": 0.011767,
     "end_time": "2021-11-08T03:17:52.695140",
     "exception": false,
     "start_time": "2021-11-08T03:17:52.683373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### b. Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "breeding-retailer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T03:17:52.723851Z",
     "iopub.status.busy": "2021-11-08T03:17:52.722745Z",
     "iopub.status.idle": "2021-11-08T03:18:37.493585Z",
     "shell.execute_reply": "2021-11-08T03:18:37.494364Z",
     "shell.execute_reply.started": "2021-11-08T01:59:45.309477Z"
    },
    "papermill": {
     "duration": 44.787365,
     "end_time": "2021-11-08T03:18:37.494584",
     "exception": false,
     "start_time": "2021-11-08T03:17:52.707219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train points and labels (5702, 2) (5702,)\n",
      "Shape of validation points and labels (316, 2) (316,)\n"
     ]
    }
   ],
   "source": [
    "with open('../input/siim-fisabio-rsna-classification-tl/train.npy', 'rb') as f:\n",
    "    points_train = np.load(f)\n",
    "    labels_train = np.load(f)\n",
    "print('Train points and labels',points.shape, labels.shape)\n",
    "\n",
    "with open('../input/siim-fisabio-rsna-classification-tl/val.npy', 'rb') as f:\n",
    "    points = np.load(f)\n",
    "    labels = np.load(f)\n",
    "print('Shape of validation points and labels',points.shape, labels.shape)\n",
    "\n",
    "# Using the same variable names for ease and memory efficiency\n",
    "X1v =np.zeros([len(labels)])\n",
    "X2v =np.zeros([len(labels)])\n",
    "yv =np.zeros([len(labels)])\n",
    "index_0 =0\n",
    "index_1=0\n",
    "ms_distance = np.zeros([len(labels_train),2])\n",
    "\n",
    "for validation_index in range(len(labels)):\n",
    "    point = points[validation_index,:]\n",
    "    \n",
    "    for iter1 in range(len(labels_train)):\n",
    "        ms_distance[iter1,:] = [np.mean(np.power(point- points_train[iter1,:],2)), labels_train[iter1]]\n",
    "\n",
    "    sorted_array = ms_distance[np.argsort(ms_distance[:, 0])]\n",
    "\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for iter1 in range(k_nearest):\n",
    "        numerator = numerator + sorted_array[iter1,1]/(distance_offset + sorted_array[iter1,0]) # numerator increases only for label=1 \n",
    "        denominator = denominator + 1/(distance_offset + sorted_array[iter1,0])\n",
    "\n",
    "    opacity_probability = numerator/denominator\n",
    "    \n",
    "    X1v[validation_index] = point[0]\n",
    "    X2v[validation_index] = point[1]\n",
    "    yv[validation_index] = opacity_probability\n",
    "    #print([point[0], point[1], opacity_probability])  \n",
    "    \n",
    "    \n",
    "dict = {'Input1': X1v, 'Input2': X2v, 'Output': yv}  \n",
    "df = pd.DataFrame(dict) \n",
    "df.to_csv('Data_Val.csv', header=True, index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-ceramic",
   "metadata": {
    "papermill": {
     "duration": 0.012011,
     "end_time": "2021-11-08T03:18:37.519519",
     "exception": false,
     "start_time": "2021-11-08T03:18:37.507508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### c. Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "provincial-alexander",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T03:18:37.547179Z",
     "iopub.status.busy": "2021-11-08T03:18:37.546491Z",
     "iopub.status.idle": "2021-11-08T03:19:22.078265Z",
     "shell.execute_reply": "2021-11-08T03:19:22.077555Z",
     "shell.execute_reply.started": "2021-11-08T02:00:15.775226Z"
    },
    "papermill": {
     "duration": 44.546842,
     "end_time": "2021-11-08T03:19:22.078457",
     "exception": false,
     "start_time": "2021-11-08T03:18:37.531615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train points and labels (316, 2) (316,)\n",
      "Shape of validation points and labels (316, 2) (316,)\n"
     ]
    }
   ],
   "source": [
    "with open('../input/siim-fisabio-rsna-classification-tl/train.npy', 'rb') as f:\n",
    "    points_train = np.load(f)\n",
    "    labels_train = np.load(f)\n",
    "print('Train points and labels',points.shape, labels.shape)\n",
    "\n",
    "with open('../input/siim-fisabio-rsna-classification-tl/test.npy', 'rb') as f:\n",
    "    points = np.load(f)\n",
    "    labels = np.load(f)\n",
    "print('Shape of validation points and labels',points.shape, labels.shape)\n",
    "\n",
    "# Using the same variable names for ease and memory efficiency\n",
    "X1t =np.zeros([len(labels)])\n",
    "X2t =np.zeros([len(labels)])\n",
    "yt =np.zeros([len(labels)])\n",
    "index_0 =0\n",
    "index_1=0\n",
    "ms_distance = np.zeros([len(labels_train),2])\n",
    "\n",
    "for validation_index in range(len(labels)):\n",
    "    point = points[validation_index,:]\n",
    "    \n",
    "    for iter1 in range(len(labels_train)):\n",
    "        ms_distance[iter1,:] = [np.mean(np.power(point- points_train[iter1,:],2)), labels_train[iter1]]\n",
    "\n",
    "    sorted_array = ms_distance[np.argsort(ms_distance[:, 0])]\n",
    "\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for iter1 in range(k_nearest):\n",
    "        numerator = numerator + sorted_array[iter1,1]/(distance_offset + sorted_array[iter1,0])\n",
    "        denominator = denominator + 1/(distance_offset + sorted_array[iter1,0])\n",
    "\n",
    "    opacity_probability = numerator/denominator\n",
    "    \n",
    "    X1t[validation_index] = point[0]\n",
    "    X2t[validation_index] = point[1]\n",
    "    yt[validation_index] = opacity_probability\n",
    "    #print([point[0], point[1], opacity_probability])  \n",
    "    \n",
    "    \n",
    "dict = {'Input1': X1t, 'Input2': X2t, 'Output': yt}  \n",
    "df = pd.DataFrame(dict) \n",
    "df.to_csv('Data_Test.csv', header=True, index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-workshop",
   "metadata": {
    "papermill": {
     "duration": 0.012282,
     "end_time": "2021-11-08T03:19:22.105649",
     "exception": false,
     "start_time": "2021-11-08T03:19:22.093367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adjusted-attack",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T03:19:22.135340Z",
     "iopub.status.busy": "2021-11-08T03:19:22.134253Z",
     "iopub.status.idle": "2021-11-08T03:19:22.183945Z",
     "shell.execute_reply": "2021-11-08T03:19:22.184478Z",
     "shell.execute_reply.started": "2021-11-08T02:00:46.399469Z"
    },
    "papermill": {
     "duration": 0.066323,
     "end_time": "2021-11-08T03:19:22.184703",
     "exception": false,
     "start_time": "2021-11-08T03:19:22.118380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input1</th>\n",
       "      <th>Input2</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.606012</td>\n",
       "      <td>0.482524</td>\n",
       "      <td>0.660340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.005259</td>\n",
       "      <td>0.880387</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.191841</td>\n",
       "      <td>-0.276844</td>\n",
       "      <td>0.304706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.922519</td>\n",
       "      <td>0.796420</td>\n",
       "      <td>0.945098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.951401</td>\n",
       "      <td>0.839575</td>\n",
       "      <td>0.791186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Input1    Input2    Output\n",
       "0 -0.606012  0.482524  0.660340\n",
       "1 -1.005259  0.880387  1.000000\n",
       "2  0.191841 -0.276844  0.304706\n",
       "3 -0.922519  0.796420  0.945098\n",
       "4 -0.951401  0.839575  0.791186"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv_path = './Data_Train.csv'\n",
    "test_csv_path = './Data_Test.csv'\n",
    "val_csv_path = './Data_Val.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "seasonal-frost",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T03:19:23.276589Z",
     "iopub.status.busy": "2021-11-08T03:19:23.275448Z",
     "iopub.status.idle": "2021-11-08T03:19:25.321737Z",
     "shell.execute_reply": "2021-11-08T03:19:25.320515Z",
     "shell.execute_reply.started": "2021-11-08T02:00:46.436206Z"
    },
    "papermill": {
     "duration": 3.12359,
     "end_time": "2021-11-08T03:19:25.321945",
     "exception": false,
     "start_time": "2021-11-08T03:19:22.198355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "tensor(1.) tensor(0.) tensor([1.6996, 1.2725]) tensor([-1.3708, -1.7394])\n",
      "tensor([3.0704, 3.0119]) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "input_=[]\n",
    "output_=[]\n",
    "for row in train_df.iloc:\n",
    "    input_.append((row[0:len(row)-1]).astype(float))\n",
    "    output_.append(row[-1])\n",
    "    \n",
    "i_val=[]\n",
    "o_val=[]\n",
    "for row in val_df.iloc:\n",
    "    i_val.append((row[0:len(row)-1]).astype(float))\n",
    "    o_val.append(row[-1])\n",
    "    \n",
    "num_input = len(row)-1;\n",
    "print(num_input)\n",
    "\n",
    "####################################################\n",
    "#\n",
    "# This code is written with the help of the demo:\n",
    "# https://medium.com/@benjamin.phillips22/simple-regression-with-neural-networks-in-pytorch-313f06910379\n",
    "#\n",
    "####################################################\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "\n",
    "torch.manual_seed(1)    # reproducible\n",
    "\n",
    "x = torch.tensor(input_).float()  \n",
    "y = torch.tensor(output_).float()   \n",
    "new_shape = (len(y), 1)\n",
    "y = y.view(new_shape)\n",
    "\n",
    "\n",
    "i_val = torch.tensor(i_val).float()  \n",
    "o_val = torch.tensor(o_val).float()   \n",
    "new_shape = (len(o_val), 1)\n",
    "o_val = o_val.view(new_shape)\n",
    "\n",
    "\n",
    "\n",
    "max_y = torch.max(y[:,0])\n",
    "min_y =torch.min(y[:,0])\n",
    "\n",
    "max_x = torch.max(x,dim=0)\n",
    "min_x = torch.min(x,dim=0)\n",
    "\n",
    "print(max_y, min_y, max_x.values, min_x.values)\n",
    "\n",
    "range_y = max_y - min_y\n",
    "range_x = max_x.values - min_x.values\n",
    "\n",
    "print(range_x, range_y)\n",
    "\n",
    "    #Normalizing\n",
    "x = (x - min_x.values)/range_x\n",
    "y = (y - min_y)/range_y\n",
    "\n",
    "    #Normalizing\n",
    "i_val = (i_val - min_x.values)/range_x\n",
    "o_val = (o_val - min_y)/range_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-premium",
   "metadata": {
    "papermill": {
     "duration": 0.013121,
     "end_time": "2021-11-08T03:19:25.348771",
     "exception": false,
     "start_time": "2021-11-08T03:19:25.335650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "trying-facility",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T03:19:25.389115Z",
     "iopub.status.busy": "2021-11-08T03:19:25.388269Z",
     "iopub.status.idle": "2021-11-08T03:22:29.764793Z",
     "shell.execute_reply": "2021-11-08T03:22:29.765359Z"
    },
    "papermill": {
     "duration": 184.403509,
     "end_time": "2021-11-08T03:22:29.765560",
     "exception": false,
     "start_time": "2021-11-08T03:19:25.362051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=2, out_features=500, bias=True)\n",
      "  (hidden2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (predict): Linear(in_features=500, out_features=1, bias=True)\n",
      ")\n",
      "Epoch [200/2000], Loss: 0.0191, Minimum Loss 0.019132, Val Loss 0.016824  \n",
      "Epoch [400/2000], Loss: 0.0190, Minimum Loss 0.019012, Val Loss 0.016766  \n",
      "Epoch [600/2000], Loss: 0.0190, Minimum Loss 0.018953, Val Loss 0.016766  \n",
      "Epoch [800/2000], Loss: 0.0189, Minimum Loss 0.018914, Val Loss 0.016750  \n",
      "Epoch [1000/2000], Loss: 0.0190, Minimum Loss 0.018896, Val Loss 0.016750  \n",
      "Epoch [1200/2000], Loss: 0.0189, Minimum Loss 0.018861, Val Loss 0.016750  \n",
      "Epoch [1400/2000], Loss: 0.0189, Minimum Loss 0.018838, Val Loss 0.016750  \n",
      "Epoch [1600/2000], Loss: 0.0189, Minimum Loss 0.018811, Val Loss 0.016729  \n",
      "Epoch [1800/2000], Loss: 0.0189, Minimum Loss 0.018779, Val Loss 0.016729  \n",
      "Epoch [2000/2000], Loss: 0.0190, Minimum Loss 0.018752, Val Loss 0.016729  \n"
     ]
    }
   ],
   "source": [
    "# torch can only train on Variable, so convert them to Variable\n",
    "x, y = Variable(x), Variable(y)\n",
    " \n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.hidden2 = torch.nn.Linear(n_hidden, n_hidden)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "\n",
    "# use the same net as before      \n",
    "net = Net(n_feature=num_input, n_hidden=500, n_output=1)     # define the network\n",
    "print(net)  # net architecture\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "\n",
    "\n",
    "minimum_train_loss = 1e5\n",
    "minimum_val_loss = 1e5\n",
    "EPOCH = 2000\n",
    "\n",
    "# start training\n",
    "for epoch in range(EPOCH):\n",
    "  \n",
    "    prediction = net(x)     # input x and predict based on x\n",
    "\n",
    "    loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    \n",
    "    if loss<minimum_train_loss:\n",
    "        minimum_train_loss =loss\n",
    "        net_opt = net\n",
    "    \n",
    "    if epoch%200 == 199:\n",
    "      prediction = net_opt(i_val)\n",
    "      loss_val = loss_func(prediction, o_val)\n",
    "      if loss_val<minimum_val_loss:\n",
    "        minimum_val_loss = loss_val\n",
    "        net_opt_val = net_opt\n",
    "      print (\"Epoch [{}/{}], Loss: {:.4f}, Minimum Loss {:.6f}, Val Loss {:.6f}  \"  .format(epoch+1, EPOCH, loss, minimum_train_loss, minimum_val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-classic",
   "metadata": {
    "papermill": {
     "duration": 0.022512,
     "end_time": "2021-11-08T03:22:29.804721",
     "exception": false,
     "start_time": "2021-11-08T03:22:29.782209",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. NN Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fatty-novelty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T03:22:29.871151Z",
     "iopub.status.busy": "2021-11-08T03:22:29.866390Z",
     "iopub.status.idle": "2021-11-08T03:22:29.955582Z",
     "shell.execute_reply": "2021-11-08T03:22:29.956180Z"
    },
    "papermill": {
     "duration": 0.12557,
     "end_time": "2021-11-08T03:22:29.956381",
     "exception": false,
     "start_time": "2021-11-08T03:22:29.830811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Test Loss 0.01677799\n",
      "Test Loss 0.01677799\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "i_test=[]\n",
    "o_test=[]\n",
    "for row in val_df.iloc:\n",
    "    i_test.append((row[0:len(row)-1]).astype(float))\n",
    "    o_test.append(row[-1])\n",
    "\n",
    "\n",
    "   \n",
    "i_test, o_test = Variable(torch.tensor(i_test)).float(), Variable(torch.tensor(o_test).float())\n",
    "new_shape = (len(o_test), 1)\n",
    "o_test = o_test.view(new_shape)\n",
    "\n",
    "    #Normalizing\n",
    "i_test = (i_test - min_x.values)/range_x\n",
    "o_test = (o_test - min_y)/range_y\n",
    "\n",
    "prediction = net_opt_val(i_test)\n",
    "loss_test = loss_func(prediction, o_test)\n",
    "\n",
    "print(\"Normalized Test Loss\",loss_test.detach().numpy())\n",
    "\n",
    "loss_test = loss_test*range_y*range_y # As the loss function returns MSE\n",
    "\n",
    "print(\"Test Loss\",loss_test.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-pakistan",
   "metadata": {
    "papermill": {
     "duration": 0.017179,
     "end_time": "2021-11-08T03:22:29.992741",
     "exception": false,
     "start_time": "2021-11-08T03:22:29.975562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "continued-story",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T03:22:30.033146Z",
     "iopub.status.busy": "2021-11-08T03:22:30.032439Z",
     "iopub.status.idle": "2021-11-08T03:22:30.040623Z",
     "shell.execute_reply": "2021-11-08T03:22:30.041181Z"
    },
    "papermill": {
     "duration": 0.030919,
     "end_time": "2021-11-08T03:22:30.041360",
     "exception": false,
     "start_time": "2021-11-08T03:22:30.010441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Guideline for loading model in future \\n\\nimport sys\\nsys.modules[__name__].__dict__.clear()\\n\\ndevice = torch.device('cpu')\\nnet = Net(n_feature=num_input, n_hidden=500, n_output=1)\\n\\nnet.load_state_dict(torch.load(PATH, map_location=device))\\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "PATH = \"./best_model_S.pt\"\n",
    "torch.save(net_opt_val.state_dict(), PATH)\n",
    "\n",
    "\n",
    "'''\n",
    "#Guideline for loading model in future \n",
    "\n",
    "import sys\n",
    "sys.modules[__name__].__dict__.clear()\n",
    "\n",
    "device = torch.device('cpu')\n",
    "net = Net(n_feature=num_input, n_hidden=500, n_output=1)\n",
    "\n",
    "net.load_state_dict(torch.load(PATH, map_location=device))\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1088.274506,
   "end_time": "2021-11-08T03:22:31.072409",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-08T03:04:22.797903",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
